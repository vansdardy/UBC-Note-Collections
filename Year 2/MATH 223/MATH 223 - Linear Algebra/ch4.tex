\section{Linear Maps and Matrices, 线性映射与矩阵}
\subsection{Linear Maps, 线性映射}
\begin{definition}
    Let $V$ and $W$ be vector spaces over $\F$, a map:
    $$f: V \to W$$
    is called a \textbf{\textbf{linear transformation}}（线性变换） if it satisfies:
    $$\forall x, y \in V, f(x+y) = f(x) + f(y)$$
    $$\forall \lambda \in \F, x \in V, f(\lambda x) = \lambda f(x)$$
\end{definition}
This linear map is also called a \textbf{\textit{homomorphism}}（同态）. \\
The set of homomorphisms between $V$ and $W$ also forms a vector space over $\F$, denoted as:
$$\Hom_\F(V, W):=\{f: V \to W\}$$
with addition and multiplication to be defined as
$$+: (f+g)(v) = f(v) + g(v)$$
$$\cdot: (\lambda f)(v) = \lambda f(v)$$
More on notations of linear maps,
\begin{definition}
    A linear map $f: V \to W$ is called: \\
    a \textbf{\textit{monomorphism}}（单态射） if it is injective; \\
    an \textbf{\textit{epimorphism}} （满态射）if it is surjective; \\
    an \textbf{\textit{isomorphism}} （同构）if it is bijective; \\
    an \textbf{\textit{endomorphism}} （自同态）if $V = W$; \\
    an \textbf{\textit{automorphism}} （自同构）if it is bijective and $V = W$
\end{definition}
More on an isomorphism, it means that if $f$ is an isomorphism, then these necessarily follows:
\begin{quote}
    $f$ is linear. \\
    There exists $g:W \to V$, such that $f \circ g = \id_W$ and $g \circ f = \id_V$. \\
    Given $\{v_1,\dots,v_n\}$ to be the basis of $V$, $\{f(v_1),\dots,f(v_n)\}$ is a basis of $W$, the converse is true as well.
\end{quote}
We then call $g$ the inverse of $f$, and we can denote it as $f^{-1}$. \\
Moreover, any two $n$-dimensional vector space over the same field $\F$ are isomorphic. \\
Linear maps between two $n$-dimensional spaces are surjective if and only if they are injective. \\
\\
We are then interested in some special spaces of these linear maps, 
\begin{definition}
    Let $f: V \to W$ be a linear map, then: \\
    the \textbf{\textit{kernel}}（核，零空间） of $f$ is defined as
    $$\Ker f := \{v \in V: f(v) = 0\}$$
    the \textbf{\textit{image}}（像） of $f$ is defined as
    $$\im f := \{f(v): v \in V\}$$
    Then, naturally, $\Ker f \subset V$,$\im f \subset W$.
\end{definition}
We then define a feature about the image of $f$,
\begin{definition}
    The \textbf{\textit{rank}}（秩） of the linear map $f$ is defined to be
    $$\rk f := \dim (\im f)$$
\end{definition}
This then will give us an extremely useful theorem,
\begin{theorem}
    The \textbf{\textit{rank-nullity theorem}}（秩——零化度定理） states that:
    $$\rk f + \dim (\im f) = \dim V$$
\end{theorem}
If we further consider the image of $f$, then given $\{v_1,\dots,v_n\}$ to be the basis of $V$, there exists a unique set of vectors $\{w_1, \dots, w_n\}$ such that for every $i=1,\dots, n$, $f(v_i)=w_i$.

\subsection{Matrices, 矩阵}
Consider a general $m\times n$ matrix, where $m$ is the number of rows, and $n$ is the number of columns,
$$A = (a_{ij}) =
\begin{pmatrix}
    a_{11} & \dots & a_{1n} \\
    \vdots & & \vdots \\
    a_{m1} & \dots & a_{mn}
\end{pmatrix}
$$
If we define $M_{m \times n}(\F)$ to be the set of all $m \times n$ matrices with entries in $\F$, then naturally, $A \in M_{m \times n}(\F)$, and we can build a \textbf{bijective} map
$$L: \Hom_\F(V, W) \to M_{m \times n}(\F)$$
so that each linear map (homomorphism) between $V$ and $W$ can be represented as a $m \times n$ matrix, given that $\dim V = n$ and $\dim W = m$. \\
If $v \in V$ and $v = \lambda_1 v_1 + \dots + \lambda_n v_n$ given the basis of $V$ to be $\{v_1, \dots, v_n\}$, then by writing the coefficients in a column, we can represent
$$v = 
\begin{pmatrix}
    \lambda_1 \\
    \vdots \\
    \lambda_n
\end{pmatrix}$$
Then,
$$Av = 
\begin{pmatrix}
    a_{11} & \dots & a_{1n} \\
    \vdots & & \vdots \\
    a_{m1} & \dots & a_{mn}
\end{pmatrix}
\begin{pmatrix}
    \lambda_1 \\
    \vdots \\
    \lambda_n
\end{pmatrix}
=
\begin{pmatrix}
    \sum_{i=1}^n a_{1i}\lambda_i \\
    \vdots \\
    \sum_{i=1}^n a_{mi}\lambda_i
\end{pmatrix}$$
The general rule behind any matrix calculation is \textbf{row $\times$ column}. \\
Thus, essentially, a $m \times n$ matrix is map $\F^n \to \F^m$. \\
By the above arithmetic rule, we can know that
\begin{quote}
    The columns of a matrix are the images of the \textbf{unit vectors}, $e_1, \dots, e_n$.
\end{quote}
From above, by choosing a basis in $V$, not only did we get a coordinate system in $V$, but also we can write any vector in $V$ as a column with entries in the field, that is choosing an isomorphism $\F^n \to V$, where
\begin{definition}
    A \textbf{\textit{canonical basis isomorphism}} is defined to be
    \begin{align*}
        \Phi_{\{v_1,\dots, v_n\}}: \F^n & \to V \\
        (\lambda_1, \dots, \lambda_n) & \mapsto \lambda_1 v_1 + \dots + \lambda_n v_n
    \end{align*}
    if we have chosen the basis of $V$ to be $\{v_1,\dots, v_n\}$.
\end{definition}
Now, since we can write any linear map as a matrix, then if we choose the basis of $V$ to be $\{v_1,\dots, v_n\}$ and the basis of $W$ to be $\{w_1,\dots, w_m\}$, where $f: V \to W$, $A$ represents $f$, then the entries of the $i^{th}$ column of $A$ is the coordinate of $Av_i$ in terms of $\{w_1,\dots, w_m\}$. That is
$$f(v_i) = Av_i = a_{1i}w_1 + \dots + a_{mi}w_m$$
The following commutative diagram can assist in understanding:
$$\begin{tikzcd}
    \F^n \arrow[r, "A"] \arrow[d, "\Phi_{\{v_1,\dots, v_n\}}"]
        & \F^m \arrow[d, "\Phi_{\{w_1,\dots, w_m\}}"] \\
    V \arrow [r, "f"]
        & W
\end{tikzcd}$$
The last thing to highlight is that consider the previously mentioned map $L$, if we know $L(f) = A$, then
\begin{definition}
    The \textbf{\textit{rank}} of a matrix $A$ is its column rank, that is, the maximal number of linearly independent columns,
    $$\rk A = \rk f$$
    given the above assumption. \\
    Similarly, the row rank of the same matrix is the maximal number of linearly independent rows.
\end{definition}
\begin{theorem}
    Given a matrix $A$, its column rank $=$ its row rank.
\end{theorem}
\newpage